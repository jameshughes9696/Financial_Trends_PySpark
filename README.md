# S&P 500 Stock Analysis with PySpark

## Overview

This project analyzes 5 years of historical S&P 500 stock data using PySpark. It performs in-depth data cleaning, aggregation, and visualization to uncover market trends, volatility, and crash-recovery patterns.

## Key Features

- Loads large CSV dataset efficiently with PySpark.
- Cleans and preprocesses stock price data.
- Extracts date components for time series analysis.
- Calculates yearly average closing prices and volatility.
- Visualizes data trends using Seaborn and Matplotlib.
- Performs crash and recovery analysis on market dips.
- Generates heatmaps and boxplots for detailed insights.

## Learning Highlights

- Gained practical experience with PySpark DataFrame operations.
- Learned how to handle large datasets efficiently in a distributed environment.
- Explored advanced grouping, aggregation, and statistical functions.
- Integrated PySpark with Python plotting libraries for clear data visualization.

## Next Steps

My next project will focus on joining multiple financial datasets to enrich analysis, including sentiment analysis on financial news data to better understand market sentiment and its impact on stock prices.